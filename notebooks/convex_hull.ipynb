{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates integration of functionality from SNT with Python through pyimagej.  \n",
    "Here's what we will accomplish:\n",
    "1. Generate a convex hull of the axon terminals within a specific brain region\n",
    "2. Compare the volume of this convex hull to the volume of the encompasing Allen CCF compartment.\n",
    "3. Do PCA on the point cloud of the relevant axon terminals.\n",
    "4. Visualize the results of these operations using Reconstruction Viewer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "#!conda install --yes --prefix {sys.prefix} -c conda-forge pyimagej openjdk=8 scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imagej\n",
    "import math\n",
    "import scipy\n",
    "import trimesh\n",
    "import numpy as np\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Fiji with GUI support.\n",
    "ij = imagej.init(r'C:\\Users\\cam\\Desktop\\Fiji.app', headless=False)\n",
    "\n",
    "from jnius import autoclass, cast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant SNT (Java) classes.\n",
    "# https://morphonets.github.io/SNT/sc/fiji/snt/io/MouseLightLoader.html\n",
    "MouseLightLoader = autoclass('sc.fiji.snt.io.MouseLightLoader')\n",
    "# https://morphonets.github.io/SNT/sc/fiji/snt/Tree.html\n",
    "Tree = autoclass('sc.fiji.snt.Tree')\n",
    "# https://morphonets.github.io/SNT/sc/fiji/snt/util/PointInImage.html\n",
    "PointInImage = autoclass('sc.fiji.snt.util.PointInImage')\n",
    "# https://morphonets.github.io/SNT/sc/fiji/snt/analysis/TreeAnalyzer.html\n",
    "TreeAnalyzer = autoclass('sc.fiji.snt.analysis.TreeAnalyzer')\n",
    "# https://morphonets.github.io/SNT/sc/fiji/snt/annotation/AllenCompartment.html\n",
    "AllenCompartment = autoclass('sc.fiji.snt.annotation.AllenCompartment')\n",
    "# https://morphonets.github.io/SNT/sc/fiji/snt/viewer/Viewer3D.html\n",
    "Viewer3D = autoclass('sc.fiji.snt.viewer.Viewer3D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_compartment_terminals(tree):\n",
    "    \"\"\"Finds the AllenCompartment containing the largest number \n",
    "    of axon terminal nodes and returns a collection containing \n",
    "    these nodes as well as the id of the relevant AllenCompartment\"\"\"\n",
    "    \n",
    "    # Use TreeAnalyzer to extract the terminal nodes from the Tree.\n",
    "    # The returned object is a Java Set containing PointInImage objects.\n",
    "    # https://docs.oracle.com/javase/7/docs/api/java/util/Set.html\n",
    "    # https://morphonets.github.io/SNT/sc/fiji/snt/util/PointInImage.html\n",
    "    tips = TreeAnalyzer(tree).getTips()\n",
    "    # We will store a list of the endpoints for each target brain region in a dictionary,\n",
    "    # where the keys are the integer ids of the brain region compartments.\n",
    "    compartment_dict = defaultdict(list)\n",
    "    # Use pyimagej to convert the Java collection to the equivalent construct in Python\n",
    "    # so that we may iterate over it.\n",
    "    for t in ij.py.from_java(tips):\n",
    "        # Get the BrainAnnotation object associated with each terminal node.\n",
    "        # https://morphonets.github.io/SNT/sc/fiji/snt/annotation/BrainAnnotation.html\n",
    "        # Since this neuron was fetched from the MouseLight database, the annotations are\n",
    "        # instances of the AllenCompartment Class.\n",
    "        annotation = t.getAnnotation()\n",
    "        if annotation is not None:\n",
    "            compartment_dict[annotation.id()].append(t)\n",
    "    # Get the compartment ID integer which contains the maximum number of axon terminals.\n",
    "    max_compartment_id = max(compartment_dict, key= lambda x: len(compartment_dict[x]))\n",
    "    # Get the associated list of terminals.\n",
    "    compartment_tips = compartment_dict[max_compartment_id]\n",
    "    \n",
    "    return compartment_tips, max_compartment_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run():\n",
    "    \n",
    "    # Fetch swc from MouseLight database by ID String.\n",
    "    loader = MouseLightLoader('AA1044')\n",
    "    if not loader.isDatabaseAvailable():\n",
    "        print(\"Could not connect to ML database\", \"Error\")\n",
    "        return\n",
    "    if not loader.idExists():\n",
    "        print(\"Somewhow the specified id was not found\", \"Error\")\n",
    "        return\n",
    "    \n",
    "    # Extract the axon sub-tree\n",
    "    tree_axon = loader.getTree(\"axon\")\n",
    "    axon_terminals, compartment_id = get_compartment_terminals(tree_axon)\n",
    "    # Use the returned compartment integer id to construct the AllenCompartment instance.\n",
    "    compartment = AllenCompartment(compartment_id)\n",
    "    # To get the convex hull of the terminal nodes using trimesh, we need to convert the Collection of PointInImage objects\n",
    "    # to their [x, y, z] coordinate representation.\n",
    "    axon_terminals_python = [[t.getX(), t.getY(), t.getZ()] for t in axon_terminals]\n",
    "    # Get the convex hull using trimesh.\n",
    "    axon_terminals_hull = trimesh.PointCloud(axon_terminals_python).convex_hull\n",
    "    # Get the vertices of the OBJMesh which represents the AllenCompartment instance.\n",
    "    # We use the right hemi-half of the mesh since this neuron projects unilaterally to the Caudoputamen.\n",
    "    # https://morphonets.github.io/SNT/sc/fiji/snt/viewer/OBJMesh.html\n",
    "    obj_mesh_vertices = compartment.getMesh().getVertices(\"right\")\n",
    "    # Convert to python list as with the axon terminals\n",
    "    obj_mesh_vertices_python = [[v.getX(), v.getY(), v.getZ()] for v in ij.py.from_java(obj_mesh_vertices)]\n",
    "    # Get the convex hull representing the hemi-half compartment.\n",
    "    obj_mesh_hull = trimesh.PointCloud(obj_mesh_vertices_python).convex_hull\n",
    "    \n",
    "    print(\"Percentage of volume taken up by the convex hull of \"\n",
    "          \"the axon terminals relative to the right Caudoputamen\")\n",
    "    print((axon_terminals_hull.volume / obj_mesh_hull.volume) * 100, \"%\")\n",
    "    \n",
    "    # Now let's visualize the results using SNT's Viewer3D.\n",
    "    viewer = Viewer3D()\n",
    "    viewer.add(tree_axon)\n",
    "    axon_hull = viewer.annotateSurface(ij.py.to_java(axon_terminals), \n",
    "                                       \"Convex Hull of Axon Terminals within {}\".format(compartment.name()))\n",
    "    axon_hull.setColor(\"orange\")\n",
    "    # We add the original compartment mesh, which contains both left and right nuclei.\n",
    "    viewer.add(compartment.getMesh())\n",
    "        \n",
    "    # As an added bonus, let's estimate the principal components of the covariance on the point cloud given \n",
    "    # by the axon terminals and annotate the resulting eigenvectors as line segments.\n",
    "    # First, subtract the mean from the points.\n",
    "    points = np.copy(axon_terminals_python)\n",
    "    mean = np.mean(points, axis=0)\n",
    "    points -= mean\n",
    "    # Compute the eigenvalues and eigenvectors of the covariance matrix.\n",
    "    e_values, e_vectors = np.linalg.eig(np.cov(points.transpose()))\n",
    "    # Construct the line segments using the eigenvectors.\n",
    "    for i in range(e_vectors.shape[1]):\n",
    "        end = mean + ((np.sqrt(e_values[i]) * 10) * e_vectors[:, i])\n",
    "        line_segment = [PointInImage(mean[0], mean[1], mean[2]), PointInImage(end[0], end[1], end[2])]\n",
    "        # Viewer3D supports adding annotations of various types.\n",
    "        # https://morphonets.github.io/SNT/sc/fiji/snt/viewer/Annotation3D.html\n",
    "        annot = viewer.annotateLine(ij.py.to_java(line_segment), \"component {}\".format(i))\n",
    "        annot.setColor(\"white\", 10)\n",
    "        annot.setSize(20)\n",
    "    \n",
    "    # Finally, we can visualize all our hard work!\n",
    "    viewer.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of volume taken up by the convex hull of the axon terminals relative to the right Caudoputamen\n",
      "3.508223713179358 %\n"
     ]
    }
   ],
   "source": [
    "run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
