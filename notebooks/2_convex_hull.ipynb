{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Volumetric Quantifications\n",
    "\n",
    "This notebook demonstrates volumetric quantifications. It assumes you have properly [setup](./README.md) your environment and ran the introductory examples. Here's what we will accomplish:\n",
    "\n",
    "1. Generate a convex hull of the axon terminals within a specific brain region\n",
    "2. Compare the volume of this convex hull to the volume of the encompasing Allen CCF compartment.\n",
    "3. Do PCA on the point cloud of the relevant axon terminals.\n",
    "4. Visualize the results of these operations using [Reconstruction Viewer](https://imagej.net/SNT:_Reconstruction_Viewer).\n",
    "\n",
    "In addition to all the packages mentioned in the [README](./README.md), [trimesh](https://trimsh.org/) is also required. If you haven't so, you can install it now:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "We'll need to 1) import Python modules; 2) initalize ij from local Fiji installation, and 3) import all relevant SNT (Java) classes: [AllenCompartment](https://morphonets.github.io/SNT/index.html?sc/fiji/snt/annotation/AllenCompartment.html), [AllenUtils](https://morphonets.github.io/SNT/index.html?sc/fiji/snt/annotation/AllenUtils.html), [MouseLightLoader](https://morphonets.github.io/SNT/index.html?sc/fiji/snt/io/MouseLightLoader.html), [PointInImage](https://morphonets.github.io/SNT/index.html?sc/fiji/snt/util/PointInImage.html), [Tree](https://morphonets.github.io/SNT/index.html?sc/fiji/snt/Tree.html), [TreeAnalyzer](https://morphonets.github.io/SNT/index.html?sc/fiji/snt/analysis/TreeAnalyzer.html), [Viewer3D](https://morphonets.github.io/SNT/index.html?sc/fiji/snt/viewer/Viewer3D.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import ijfinder\n",
    "import imagej\n",
    "import trimesh\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "fiji_path = ijfinder.getpath().decode('utf-8')\n",
    "if os.path.isdir(fiji_path):\n",
    "    ij = imagej.init(fiji_path, headless=False)\n",
    "else:\n",
    "    print(\"Cannot proceed: Fiji not found!\")\n",
    "\n",
    "from jnius import autoclass, cast\n",
    "AllenCompartment = autoclass('sc.fiji.snt.annotation.AllenCompartment')\n",
    "AllenUtils = autoclass('sc.fiji.snt.annotation.AllenUtils')\n",
    "MouseLightLoader = autoclass('sc.fiji.snt.io.MouseLightLoader')\n",
    "NodeStatistics = autoclass('sc.fiji.snt.analysis.NodeStatistics')\n",
    "PointInImage = autoclass('sc.fiji.snt.util.PointInImage')\n",
    "Tree = autoclass('sc.fiji.snt.Tree')\n",
    "TreeAnalyzer = autoclass('sc.fiji.snt.analysis.TreeAnalyzer')\n",
    "Viewer3D = autoclass('sc.fiji.snt.viewer.Viewer3D')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll define two support functions: one to download the axonal arbor of a MouseLight neuron, the other to detect the brain area that is the most innervated by its axon:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_axon(id_string):\n",
    "    \"\"\"Fetchs an axonal arbor from the MouseLight database by ID\"\"\"\n",
    "    loader = MouseLightLoader(id_string)\n",
    "    if not loader.isDatabaseAvailable():\n",
    "        print(\"Could not connect to ML database\", \"Error\")\n",
    "        return null\n",
    "    if not loader.idExists():\n",
    "        print(\"Somewhow the specified id was not found\", \"Error\")\n",
    "        return null\n",
    "    # Extract the axon sub-tree\n",
    "    return loader.getTree(\"axon\")\n",
    "\n",
    "\n",
    "def get_compartment_terminals(tree):\n",
    "    \"\"\"Finds the AllenCompartment containing the largest number \n",
    "    of axon terminal nodes and returns a collection containing \n",
    "    these nodes as well as the id of the relevant AllenCompartment\"\"\"\n",
    "    \n",
    "    # Use TreeAnalyzer to extract the terminal nodes from the Tree.\n",
    "    # Instantiate a NodeStatistics instance and retrieve a list of the endpoints for\n",
    "    # each target brain region (a BrainAnnotation) in a dictionary, where the keys are\n",
    "    # the brain annotations. Since this neuron was fetched from the MouseLight database,\n",
    "    # the annotations are instances of the AllenCompartment Class\n",
    "    # https://morphonets.github.io/SNT/sc/fiji/snt/annotation/BrainAnnotation.html\n",
    "    tips = TreeAnalyzer(tree).getTips()\n",
    "    node_stats = NodeStatistics(tips)\n",
    "    compartment_dict = ij.py.from_java(node_stats.getAnnotatedNodes())\n",
    "\n",
    "    # Get the compartment containing the maximum number of axon terminals\n",
    "    max_compartment = max(compartment_dict, key= lambda x: len(compartment_dict[x]))\n",
    "    # Get the associated list of terminals.\n",
    "    compartment_tips = compartment_dict[max_compartment]\n",
    "    \n",
    "    return compartment_tips, max_compartment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of volume occupied by the convex hull of the axon terminals with respect to the right Caudoputamen\n",
      "3.508223713179358 %\n"
     ]
    }
   ],
   "source": [
    "tree_axon = get_axon('AA1044')\n",
    "axon_terminals, compartment = get_compartment_terminals(tree_axon)\n",
    "\n",
    "# To get the convex hull of the terminal nodes using trimesh, \n",
    "# we need to convert the Collection of PointInImage objects\n",
    "# to their [x, y, z] coordinate representation as a 2D Python array.\n",
    "axon_terminals_python = [[t.getX(), t.getY(), t.getZ()] for t in axon_terminals]\n",
    "# Get the convex hull of the tips using trimesh.\n",
    "axon_terminals_hull = trimesh.PointCloud(axon_terminals_python).convex_hull\n",
    "# We can get the dominant hemi-half of the target compartment using AllenUtils.\n",
    "centroid = np.mean(axon_terminals_python, axis=0)\n",
    "hemisphere = \"left\" if AllenUtils.isLeftHemisphere(centroid[0], centroid[1], centroid[2]) else \"right\"\n",
    "# Get the vertices of the OBJMesh which represents the AllenCompartment instance.\n",
    "# https://morphonets.github.io/SNT/sc/fiji/snt/viewer/OBJMesh.html\n",
    "obj_mesh_vertices = compartment.getMesh().getVertices(hemisphere)\n",
    "# Convert to nested Python list as with the axon terminals.\n",
    "obj_mesh_vertices_python = [[v.getX(), v.getY(), v.getZ()] for v in ij.py.from_java(obj_mesh_vertices)]\n",
    "# Get the convex hull representing the hemi-half compartment.\n",
    "obj_mesh_hull = trimesh.PointCloud(obj_mesh_vertices_python).convex_hull\n",
    "\n",
    "# Now compare the volumes of the convex hulls\n",
    "print(\"Percentage of volume occupied by the convex hull of \"\n",
    "      \"the axon terminals with respect to the {} Caudoputamen\".format(hemisphere))\n",
    "print((axon_terminals_hull.volume / obj_mesh_hull.volume) * 100, \"%\")\n",
    "\n",
    "# Now we may begin adding the computed objects to SNT's Viewer3D.\n",
    "# Viewer3D has a script-friendly 'add' method which accepts a variety of differnent objects,\n",
    "# e.g., Tree, AbstractDrawable, OBJMesh, etc...\n",
    "viewer = Viewer3D()\n",
    "viewer.add(tree_axon)\n",
    "\n",
    "# Add the original compartment mesh, which contains both left and right nuclei.\n",
    "viewer.add(compartment.getMesh())\n",
    "\n",
    "# And the convex hull\n",
    "axon_hull = viewer.annotateSurface(ij.py.to_java(axon_terminals), \n",
    "                                   \"Convex Hull of Axon Terminals within {}\".format(compartment.name()))\n",
    "axon_hull.setColor(\"orange\", 95) # transparency (%)\n",
    "\n",
    "# Finally, we can visualize all our hard work!\n",
    "viewer.show()\n",
    "viewer.setAnimationEnabled(True)\n",
    "\n",
    "#To embed the snapshot in this notebook\n",
    "#snapshot_path = os.getcwd() + '/images/convexhull1.png'\n",
    "#viewer.saveSnapshot(snapshot_path)\n",
    "#from IPython.display import Image, display\n",
    "#display(Image(filename=snapshot_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./images/convexhull.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a bonus, let's estimate the principal components of the covariance on the point cloud given by the axon terminals and annotate the resulting eigenvectors as line segments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, subtract the mean from the points.\n",
    "points = np.copy(axon_terminals_python)\n",
    "points -= centroid\n",
    "# Compute the eigenvalues and eigenvectors of the covariance matrix.\n",
    "e_values, e_vectors = np.linalg.eig(np.cov(points.transpose()))\n",
    "\n",
    "# Construct the line segments using the eigenvectors.\n",
    "viewer.setAnimationEnabled(False)\n",
    "viewer.setSceneUpdatesEnabled(False)\n",
    "for i in range(e_vectors.shape[1]):\n",
    "    # The line segments will originate at the centroid of the terminals.\n",
    "    end = centroid + ((np.sqrt(e_values[i]) * 10) * e_vectors[:, i])\n",
    "    line_segment = [PointInImage(centroid[0], centroid[1], centroid[2]), PointInImage(end[0], end[1], end[2])]\n",
    "    # Viewer3D supports adding annotations of various types, and allows customization of \n",
    "    # their visual properties.\n",
    "    # https://morphonets.github.io/SNT/sc/fiji/snt/viewer/Annotation3D.html\n",
    "    annot = viewer.annotateLine(ij.py.to_java(line_segment), \"component {}\".format(i))\n",
    "    annot.setColor(\"white\", 10)\n",
    "    annot.setSize(20)\n",
    "\n",
    "viewer.setSceneUpdatesEnabled(True)\n",
    "viewer.updateView()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyimagej",
   "language": "python",
   "name": "pyimagej"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
